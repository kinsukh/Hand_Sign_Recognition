# -*- coding: utf-8 -*-
"""sentence_creater.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qv-dbpgaURJ1u0qo4-BMRrLS_vzOpKrx
"""

# !pip install transformers

from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed

import torch
torch.set_default_tensor_type(torch.cuda.FloatTensor)

model = AutoModelForCausalLM.from_pretrained("bigscience/bloom-1b7", use_cache=True)
tokenizer = AutoTokenizer.from_pretrained("bigscience/bloom-1b7")

set_seed(424242)

model.__class__.__name__

def make_sentence(prompt,max_length):
  input_ids = tokenizer(prompt, return_tensors="pt").to(0)
  sample = model.generate(**input_ids, max_length=max_length,  top_k=1, temperature=0.9, repetition_penalty = 2.0)
  print(tokenizer.decode(sample[0], truncate_before_pattern=[r"\n\n^#", "^'''", "\n\n\n"]))

make_sentence('hi',50)